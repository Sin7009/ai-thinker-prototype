import uuid
import json
import threading
from agents.task_agent import TaskAgent
from agents.detector_agent import DetectorAgent
from agents.methodology_agent import MethodologyAgent
from agents.bias_mapping import RUSSIAN_TO_INTERNAL_BIAS_MAP
from orchestrator.dynamic_memory import DynamicMemory
from orchestrator.action_library import ActionLibrary #–ù—É–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É –¥–µ–π—Å—Ç–≤–∏–π
from database.db_connector import get_chroma_collection, chroma_client
import re

import time

from langchain_core.messages import HumanMessage, SystemMessage

from .agent_mode import AgentMode

# –ê–∫—Ç—É–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤—Ç–æ—Ä–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è
MODEL_LITE = "GigaChat-2"
MODEL_SMART = "GigaChat-2-Pro"
MODEL_MAX = "GigaChat-2-Max"

class Orchestrator:
    def __init__(self, user_id_stub: str):
        self.user_id_stub = user_id_stub

        # --- –†–û–£–¢–ò–ù–ì –ú–û–î–ï–õ–ï–ô ---
        self.task_agent = TaskAgent(model_name=MODEL_LITE)
        self.detector_agent = DetectorAgent(model_name=MODEL_LITE)
        self.methodology_agent = MethodologyAgent(user_id=user_id_stub, model_name=MODEL_SMART)

        self.memory = DynamicMemory(user_id_stub, self.task_agent)
        self.mode = AgentMode.COPILOT
        self.last_user_input = ""
        self.vector_collection = get_chroma_collection(f"dialogue_vector_{user_id_stub}")
        self.action_library = ActionLibrary(self.methodology_agent)
        self.strategic_note = "" # –ó–¥–µ—Å—å –±—É–¥–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—å—Å—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –Ω–∞ —Å–µ—Å—Å–∏—é
        print(f"–û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id_stub}.")
        self._develop_strategy() # –í—ã—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ

    def _develop_strategy(self):
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Å–µ—Å—Å–∏–π –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç '—Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫—É—é –∑–∞–º–µ—Ç–∫—É'
        –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤ –≤ —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏.
        """
        recent_analyses = self.memory.get_recent_session_analyses(limit=5)
        if not recent_analyses:
            return # –°—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–µ –≤—ã—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º, –µ—Å–ª–∏ –∏—Å—Ç–æ—Ä–∏–∏ –Ω–µ—Ç

        history_summary = "\n".join(
            [f"- –°–µ—Å—Å–∏—è –æ—Ç {a.ended_at.strftime('%Y-%m-%d')}: "
             f"–¢–µ–º—ã ({a.key_topics}), –ü–∞—Ç—Ç–µ—Ä–Ω—ã ({a.identified_patterns}). "
             f"–†–µ–∑—é–º–µ: {a.session_summary}" for a in recent_analyses]
        )

        strategy_prompt = f"""
–¢—ã ‚Äî AI-—Å—Ç—Ä–∞—Ç–µ–≥. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏—Å—Ç–æ—Ä–∏—é —Å–µ—Å—Å–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –¥–∞–π –∫–æ—Ä–æ—Ç–∫—É—é (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) —Ç–∞–∫—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –¥–ª—è AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é —Å–µ—Å—Å–∏—é.

–ò—Å—Ç–æ—Ä–∏—è —Å–µ—Å—Å–∏–π:
{history_summary}

–ü—Ä–∏–º–µ—Ä —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —á–∞—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –∫ —Ç–µ–º–µ –ø—Ä–æ–∫—Ä–∞—Å—Ç–∏–Ω–∞—Ü–∏–∏, –Ω–æ —Ç–µ—Ö–Ω–∏–∫–∏ –Ω–µ –ø–æ–º–æ–≥–∞—é—Ç. –í —ç—Ç–æ—Ç —Ä–∞–∑ —Å—Ç–æ–∏—Ç –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –æ–±—Å—É–¥–∏—Ç—å –µ–≥–æ —ç–º–æ—Ü–∏–∏, –∞ –Ω–µ –∏—Å–∫–∞—Ç—å —Ä–µ—à–µ–Ω–∏—è."
–¢–≤–æ—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:
"""

        try:
            self.strategic_note = self.task_agent.process("", context_memory=strategy_prompt)
            print(f"üí° –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∞—è –∑–∞–º–µ—Ç–∫–∞ –Ω–∞ —Å–µ—Å—Å–∏—é: {self.strategic_note}")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: {e}")

    def _extract_name(self, text: str) -> str:
        """
        –ü—ã—Ç–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ—á—å –∏–º—è –∏–∑ —Ñ—Ä–∞–∑: "–ú–µ–Ω—è –∑–æ–≤—É—Ç –ö–æ—Å—Ç—è", "–Ø ‚Äî –ö–æ—Å—Ç—è", "–ö–æ—Å—Ç—è".
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–º—è –∏–ª–∏ None. –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è.
        """
        text_clean = text.strip()
        if not text_clean:
            return None

        # –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è (–≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ)
        greetings = ["–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ", "–¥–æ–±—Ä—ã–π –¥–µ–Ω—å", "–¥–æ–±—Ä–æ–µ —É—Ç—Ä–æ", "–¥–æ–±—Ä—ã–π –≤–µ—á–µ—Ä"]
        if text_clean.lower() in greetings:
            return None

        # –ü–∞—Ç—Ç–µ—Ä–Ω 1: "–∑–æ–≤—É—Ç –ö–æ—Å—Ç—è", "—è ‚Äî –ö–æ—Å—Ç—è", "—ç—Ç–æ –ö–æ—Å—Ç—è"
        match = re.search(
            # (?i:...) –¥–µ–ª–∞–µ—Ç —á–∞—Å—Ç—å –≤—ã—Ä–∞–∂–µ–Ω–∏—è –Ω–µ—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–π –∫ —Ä–µ–≥–∏—Å—Ç—Ä—É,
            # –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –∏–º—è ([–ê-–Ø–Å][–∞-—è—ë]+) –æ—Å—Ç–∞–µ—Ç—Å—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º.
            r"(?i:–∑–æ–≤—É—Ç|—ç—Ç–æ|—è[^\w]*|–º–µ–Ω—è –∑–æ–≤—É—Ç)\s+([–ê-–Ø–Å][–∞-—è—ë]+)",
            text_clean
        )
        if match:
            return match.group(1)

        # –ü–∞—Ç—Ç–µ—Ä–Ω 2: –ø—Ä–æ—Å—Ç–æ –∏–º—è (–æ–¥–Ω–æ —Å–ª–æ–≤–æ —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π, –Ω–µ –∏–∑ —Å–ø–∏—Å–∫–∞ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π)
        if re.fullmatch(r"[–ê-–Ø–Å][–∞-—è—ë]+", text_clean):
            return text_clean

        return None

    def get_greeting(self) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–æ–≥–æ, –Ω–æ–≤—ã–π –ª–∏ —ç—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å.
        """
        user_name = self.memory.get_user_name()
        last_summary = self.memory.get_last_session_summary()

        if user_name:
            greeting = f"{user_name}, —Ä–∞–¥ –≤–∞—Å —Å–Ω–æ–≤–∞ –≤–∏–¥–µ—Ç—å! "
            if last_summary:
                greeting += f"–í –ø—Ä–æ—à–ª—ã–π —Ä–∞–∑ –º—ã –≥–æ–≤–æ—Ä–∏–ª–∏ –æ —Å–ª–µ–¥—É—é—â–µ–º: '{last_summary}'. –•–æ—Ç–∏—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –∏–ª–∏ —É –≤–∞—Å –Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞?"
            else:
                greeting += "–ß–µ–º —è –º–æ–≥—É –≤–∞–º –ø–æ–º–æ—á—å —Å–µ–≥–æ–¥–Ω—è?"
        else:
            greeting = "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ß—Ç–æ–±—ã –Ω–∞—à –¥–∏–∞–ª–æ–≥ –±—ã–ª –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–µ–µ, —Å–∫–∞–∂–∏—Ç–µ, –∫–∞–∫ —è –º–æ–≥—É –∫ –≤–∞–º –æ–±—Ä–∞—â–∞—Ç—å—Å—è?"

        return greeting
    
    def _sync_agent_memories(self):
        """–ü–µ—Ä–µ–¥–∞—ë—Ç –∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Ñ–∞–∫—Ç—ã –≤ –∞–≥–µ–Ω—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"""
        # –ù–∞–ø—Ä–∏–º–µ—Ä: –µ—Å–ª–∏ –≤—ã —Ö—Ä–∞–Ω–∏—Ç–µ –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –º–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –≤ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        pass

    def _should_retrieve_memory(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∏–∑–≤–ª–µ–∫–∞—Ç—å –ø–∞–º—è—Ç—å."""
        triggers = [
            "–æ —á—ë–º –º—ã –≥–æ–≤–æ—Ä–∏–ª–∏", "—á—Ç–æ –±—ã–ª–æ", "–Ω–∞–ø–æ–º–Ω–∏", "—Ä–∞–Ω—å—à–µ –≥–æ–≤–æ—Ä–∏–ª",
            "–ø—Ä–æ—à–ª—ã–π —Ä–∞–∑", "—É–∂–µ –æ–±—Å—É–∂–¥–∞–ª–∏", "–≥–æ–≤–æ—Ä–∏–ª–∏ –ª–∏", "–ø–æ–º–Ω–∏—Ç", "–Ω–∞–ø–æ–º–Ω–∏"
        ]
        text_lower = text.lower()
        return any(trigger in text_lower for trigger in triggers)

    def _should_enter_thinking_cycle(self, text: str) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å –≤ —Ä–µ–∂–∏–º "–ü–∞—Ä—Ç–Ω—ë—Ä" (–º—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π —Ü–∏–∫–ª)
        –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        """
        triggers = [
            "–¥–∞–≤–∞–π –ø–æ–¥—É–º–∞–µ–º", "–ø–æ–º–æ–≥–∏ —Ä–µ—à–∏—Ç—å", "—á—Ç–æ –º–Ω–µ –¥–µ–ª–∞—Ç—å",
            "–Ω–µ –º–æ–≥—É –ø–æ–Ω—è—Ç—å", "–Ω—É–∂–µ–Ω —Å–æ–≤–µ—Ç", "–ø–æ–º–æ–≥–∏ —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è"
        ]
        text_lower = text.lower().strip()
        return any(trigger in text_lower for trigger in triggers)

    def _diagnose_and_select_action(self, problem_description: str) -> callable:
        """
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç LLM –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–±–ª–µ–º—ã –∏ –≤—ã–±–æ—Ä–∞ –Ω–∞–∏–ª—É—á—à–µ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è
        –∏–∑ ActionLibrary.
        """
        system_prompt = (
            "–¢—ã ‚Äî AI-–¥–∏–∞–≥–Ω–æ—Å—Ç. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –≤—ã–±—Ä–∞—Ç—å "
            "–Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â—É—é –º—ã—Å–ª–∏—Ç–µ–ª—å–Ω—É—é —Ç–µ—Ö–Ω–∏–∫—É –¥–ª—è –µ–≥–æ —Ä–µ—à–µ–Ω–∏—è. "
            "–í–æ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–µ–±–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã: "
            "1. 'run_rubber_duck_debugging': –ò—Å–ø–æ–ª—å–∑—É–π, –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞—Å—Ç—Ä—è–ª –≤ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–±–ª–µ–º–µ, "
            "–±–∞–≥–µ –≤ –∫–æ–¥–µ –∏–ª–∏ –Ω–µ –º–æ–∂–µ—Ç —è—Å–Ω–æ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–µ–π—Å—Ç–≤–∏–π. –ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è –¥–µ–±–∞–≥–≥–∏–Ω–≥–∞. "
            "2. 'run_five_whys': –ò—Å–ø–æ–ª—å–∑—É–π, –∫–æ–≥–¥–∞ –ø—Ä–æ–±–ª–µ–º–∞ –∫–∞–∂–µ—Ç—Å—è –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–Ω–æ–π, –∏ –Ω—É–∂–Ω–æ –¥–æ–∫–æ–ø–∞—Ç—å—Å—è –¥–æ "
            "–≥–ª—É–±–∏–Ω–Ω–æ–π, –∫–æ—Ä–Ω–µ–≤–æ–π –ø—Ä–∏—á–∏–Ω—ã. –û—Ç–ª–∏—á–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∏–ª–∏ –ª–∏—á–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º. "
            "3. 'run_constrained_brainstorming': –ò—Å–ø–æ–ª—å–∑—É–π, –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∂–∞–ª—É–µ—Ç—Å—è –Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∏–¥–µ–π, "
            "—Ç–≤–æ—Ä—á–µ—Å–∫–∏–π —Å—Ç—É–ø–æ—Ä –∏–ª–∏ '–ø–∞—Ä–∞–ª–∏—á —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞'. "
            "–í –æ—Ç–≤–µ—Ç —Ç—ã –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å –¢–û–õ–¨–ö–û –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—É—é –Ω—É–∂–Ω–æ –≤—ã–∑–≤–∞—Ç—å. –ù–∞–ø—Ä–∏–º–µ—Ä: 'run_five_whys'."
        )

        # –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º TaskAgent –∫–∞–∫ "–º–æ–∑–≥" –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏
        raw_response = self.task_agent.process(problem_description, context_memory=system_prompt)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ –æ—Ç–≤–µ—Ç–∞
        action_name = raw_response.strip()

        # –ü–æ–ª—É—á–∞–µ–º —Å–∞–º—É —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ ActionLibrary
        action_function = getattr(self.action_library, action_name, None)

        if action_function and callable(action_function):
            return action_function
        else:
            # –ï—Å–ª–∏ LLM –≤–µ—Ä–Ω—É–ª —á—Ç–æ-—Ç–æ –Ω–µ —Ç–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º "—É—Ç–µ–Ω–∫–∞" –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            return self.action_library.run_rubber_duck_debugging

    def _normalize_text(self, text: str) -> str:
        """–£–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã, –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É."""
        return re.sub(r'[^\w\s]', '', text.lower().strip())

    def _should_report_memory(self, text: str) -> bool:
        text_norm = self._normalize_text(text)
        triggers = [
            "—Ä–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ –º–µ–Ω—è",
            "—á—Ç–æ —Ç—ã –æ–±–æ –º–Ω–µ –∑–Ω–∞–µ—à—å",
            "—á—Ç–æ —Ç—ã –æ–±–æ –º–Ω–µ –ø–æ–º–Ω–∏—à—å",
            "—á—Ç–æ —Ç—ã –ø–æ–º–Ω–∏—à—å",
            "—á—Ç–æ —Ç—ã –∑–Ω–∞–µ—à—å",
            "–Ω–∞–ø–æ–º–Ω–∏",
            "–æ —á—ë–º –º—ã –≥–æ–≤–æ—Ä–∏–ª–∏",
            "—á—Ç–æ –±—ã–ª–æ",
            "—É–∂–µ –æ–±—Å—É–∂–¥–∞–ª–∏",
            "—á—Ç–æ –æ–±–æ –º–Ω–µ"
        ]
        return any(trigger in text_norm for trigger in triggers)


    
    def _run_analysis_in_background(self, text: str):
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Å–∏—Ö–æ–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –≤ —Ñ–æ–Ω–æ–≤–æ–º –ø–æ—Ç–æ–∫–µ
        –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.
        """

        # –ñ–¥–µ–º 3 —Å–µ–∫—É–Ω–¥—ã, —á—Ç–æ–±—ã –æ—Å–Ω–æ–≤–Ω–æ–π TaskAgent —É—Å–ø–µ–ª –æ—Ç—Ä–∞–±–æ—Ç–∞—Ç—å
        # –∏ –Ω–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å –ø–∏–∫–æ–≤—É—é –Ω–∞–≥—Ä—É–∑–∫—É –Ω–∞ API
        time.sleep(3)
        try:
            analysis_data = self.detector_agent.analyze(text)
            if 'cognitive_biases' in analysis_data and isinstance(analysis_data.get('cognitive_biases'), list):
                for pattern in analysis_data['cognitive_biases']:
                    internal_name = RUSSIAN_TO_INTERNAL_BIAS_MAP.get(pattern.get('name'))
                    if internal_name:
                        self.memory.save_cognitive_pattern(
                            pattern_name=internal_name,
                            confidence=pattern.get('confidence', 0),
                            context=pattern.get('context', '')
                        )
            self.memory.save_psycholinguistic_features(
                emotional_tone=analysis_data.get('emotional_tone', '–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π'),
                communication_style=analysis_data.get('communication_style', '–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π')
            )
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–º –ø–æ—Ç–æ–∫–µ –∞–Ω–∞–ª–∏–∑–∞: {e}")

    def process_input(self, text: str) -> str:
        self.memory.save_interaction(text, is_user=True)
        self.last_user_input = text

        # üöÄ **–ù–æ–≤—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏** üöÄ

        # 1. –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø—Å–∏—Ö–æ–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (Fire-and-Forget)
        if len(text.split()) > 7:  # –ü–æ—Ä–æ–≥ –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É —Å–æ–æ–±—â–µ–Ω–∏—è
            analysis_thread = threading.Thread(target=self._run_analysis_in_background, args=(text,))
            analysis_thread.start()

        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å –æ –ø–∞–º—è—Ç–∏
        if self._should_report_memory(text):
            user_summary = self.memory.get_user_profile_summary()
            response = f"–Ø –ø–æ–º–Ω—é —Å–ª–µ–¥—É—é—â–µ–µ –æ —Ç–µ–±–µ:\n\n{user_summary}"
            self.memory.save_interaction(response, is_user=False)
            return response

        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤—Ö–æ–¥ –≤ –º—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π —Ü–∏–∫–ª
        if self._should_enter_thinking_cycle(text):
            self.switch_mode(AgentMode.PARTNER)
            response = self.handle_partner_mode(text)
            self.memory.save_interaction(response, is_user=False)
            return response

        # 4. –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø–æ —Ä–µ–∂–∏–º–∞–º
        if self.mode == AgentMode.COPILOT:
            response = self.handle_copilot_mode(text)
        elif self.mode == AgentMode.PARTNER:
            response = self.handle_partner_mode(text)
            # –ü–†–û–í–ï–†–ö–ê –ù–ê –í–´–•–û–î –ò–ó –¢–ï–•–ù–ò–ö–ò
            if "[STOP_TECHNIQUE]" in response:
                self.switch_mode(AgentMode.COPILOT)
                response = "–•–æ—Ä–æ—à–æ, –±–µ–∑ –ø—Ä–æ–±–ª–µ–º. –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ –æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º. –ß–µ–º –µ—â–µ –º–æ–≥—É –ø–æ–º–æ—á—å?"
        else:
            response = "–û—à–∏–±–∫–∞: –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã."

        # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –≤—ã–≤–æ–¥
        self.memory.save_interaction(response, is_user=False)
        self._infer_and_save_user_traits(text, response)
        return response

    def _infer_and_save_user_traits(self, user_input: str, agent_response: str):
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ–±–º–µ–Ω —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏, —á—Ç–æ–±—ã –≤—ã–≤–µ—Å—Ç–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å
        —á–µ—Ä—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è, –∏–Ω—Ç–µ—Ä–µ—Å—ã –∏ —Ç.–¥.).
        """
        system_prompt = (
            "–¢—ã ‚Äî AI-–∞–Ω–∞–ª–∏—Ç–∏–∫, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî "
            "–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∏–∞–ª–æ–≥ –∏ —Å–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ. "
            "–û—Å–Ω–æ–≤—ã–≤–∞–π—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º —Ç–µ–∫—Å—Ç–µ. "
            "–í–µ—Ä–Ω–∏ —Å–≤–æ–∏ –≤—ã–≤–æ–¥—ã –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–∞ JSON-–æ–±—ä–µ–∫—Ç–æ–≤. –ö–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å "
            "—Ç—Ä–∏ –∫–ª—é—á–∞: 'trait_type' (—Ç–∏–ø —á–µ—Ä—Ç—ã: 'preference', 'interest', 'communication_style'), "
            "'trait_description' (–æ–ø–∏—Å–∞–Ω–∏–µ —á–µ—Ä—Ç—ã) –∏ 'confidence' (—Ç–≤–æ—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –≤—ã–≤–æ–¥–µ –æ—Ç 0 –¥–æ 100). "
            "–ï—Å–ª–∏ –≤—ã–≤–æ–¥–æ–≤ –Ω–µ—Ç, –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ []."
        )

        # –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º TaskAgent –∫–∞–∫ "–º–æ–∑–≥" –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏
        # –í –±—É–¥—É—â–µ–º —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç
        dialogue_snippet = f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: ¬´{user_input}¬ª\n–ê–≥–µ–Ω—Ç: ¬´{agent_response}¬ª"

        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º TaskAgent –¥–ª—è –≤—ã–≤–æ–¥–∞
            raw_response = self.task_agent.process(dialogue_snippet, context_memory=system_prompt)

            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            json_part = raw_response[raw_response.find('['):raw_response.rfind(']')+1]
            inferred_traits = json.loads(json_part)

            for trait in inferred_traits:
                if all(k in trait for k in ['trait_type', 'trait_description', 'confidence']):
                    # –ü–æ–Ω–∏–∂–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≥–∏–ø–æ—Ç–µ–∑—ã
                    if trait['confidence'] > 50:
                        self.memory.reinforce_user_trait(
                            trait_type=trait['trait_type'],
                            trait_description=trait['trait_description'],
                            confidence=trait['confidence']
                        )
        except (json.JSONDecodeError, IndexError) as e:
            # –û—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON ‚Äî —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –µ—Å–ª–∏ LLM –æ—Ç–≤–µ—Ç–∏–ª –Ω–µ –≤ —Ç–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            # print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —á–µ—Ä—Ç—ã –∏–∑ –æ—Ç–≤–µ—Ç–∞: {raw_response}. –û—à–∏–±–∫–∞: {e}")
            pass
        except Exception as e:
            print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–≤–æ–¥–µ —á–µ—Ä—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")


    def _enrich_context(self, query: str) -> str:
        """
        –°–æ–±–∏—Ä–∞–µ—Ç –∏ –æ–±–æ–≥–∞—â–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ LLM.
        –í–∫–ª—é—á–∞–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫—É—é –∑–∞–º–µ—Ç–∫—É, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–∏–∞–ª–æ–≥–∏ (RAG) –∏ —Å–≤–æ–¥–∫—É –ø—Ä–æ—Ñ–∏–ª—è.
        """
        full_context = ""

        # 1. –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∞—è –∑–∞–º–µ—Ç–∫–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if self.strategic_note:
            full_context += f"**–¢–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –Ω–∞ —ç—Ç—É —Å–µ—Å—Å–∏—é:** {self.strategic_note}\n\n"

        # 2. RAG –∏–∑ ChromaDB
        relevant_memories = self.memory.search_memories(query, n_results=3)
        rag_context = ""
        if relevant_memories:
            rag_context = "–í–æ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏–∑ –ø—Ä–æ—à–ª—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤:\n" + "\n".join(
                [f"- ¬´{m}¬ª" for m in relevant_memories]
            )

        # 3. –°–≤–æ–¥–∫–∞ –∏–∑ SQLite
        profile_summary = self.memory.get_user_profile_summary()

        # 4. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
        if profile_summary:
            full_context += f"**–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ:**\n{profile_summary}\n\n"
        if rag_context:
            full_context += f"**–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞:**\n{rag_context}\n\n"

        return full_context

    def handle_copilot_mode(self, text: str) -> str:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä–µ–∂–∏–º "–ö–æ–ø–∏–ª–æ—Ç": –ø—Ä—è–º–æ–π –æ—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        """
        # –û–±–æ–≥–∞—â–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç, —á—Ç–æ–±—ã –¥–∞—Ç—å LLM –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        enriched_context = self._enrich_context(text)

        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä—è–º–æ–π –æ—Ç–≤–µ—Ç –æ—Ç TaskAgent
        response = self.task_agent.process(text, context_memory=enriched_context)
        return response

    def handle_partner_mode(self, text: str) -> str:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä–µ–∂–∏–º "–ü–∞—Ä—Ç–Ω—ë—Ä": –∑–∞–ø—É—Å–∫–∞–µ—Ç –º—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π —Ü–∏–∫–ª.
        –î–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –∏ –≤—ã–±–∏—Ä–∞–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â—É—é —Ç–µ—Ö–Ω–∏–∫—É –∏–∑ ActionLibrary.
        """
        # 1. –î–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º—É –∏ –≤—ã–±–∏—Ä–∞–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        action_to_run = self._diagnose_and_select_action(text)

        # 2. –ó–∞–ø—É—Å–∫–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
        # –ú–µ—Ç–æ–¥ –∏–∑ ActionLibrary —Å–∞–º –≤—ã–∑–æ–≤–µ—Ç MethodologyAgent —Å –Ω—É–∂–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
        response = action_to_run(text)

        return response
    
    def switch_mode(self, new_mode: AgentMode):
        """–ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞."""
        self.mode = new_mode
        if new_mode == AgentMode.COPILOT:
            # –ü—Ä–∏ –≤—ã—Ö–æ–¥–µ –∏–∑ —Ä–µ–∂–∏–º–∞ "–ü–∞—Ä—Ç–Ω–µ—Ä" –º–æ–∂–Ω–æ –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å –∞–≥–µ–Ω—Ç–∞ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–π
            self.methodology_agent.clear_memory()
            print("–†–µ–∂–∏–º –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: COPILOT. –°–µ—Å—Å–∏—è –ø–∞—Ä—Ç–Ω—ë—Ä—Å—Ç–≤–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
        else:
            print(f"–†–µ–∂–∏–º –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: {self.mode.value}.")

    def reset_all_memory(self):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç –≤—Å—é –ø–∞–º—è—Ç—å, –≤–∫–ª—é—á–∞—è TaskAgent –∏ MethodologyAgent."""
        self.task_agent.clear_memory()
        self.methodology_agent.clear_memory()
        print("–í—Å—è –ø–∞–º—è—Ç—å –∞–≥–µ–Ω—Ç–æ–≤ –æ—á–∏—â–µ–Ω–∞.")

    def _analyze_and_save_session(self):
        """
        –ü—Ä–æ–≤–æ–¥–∏—Ç –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–π —Å–µ—Å—Å–∏–∏, –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã –∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã,
        –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.
        """
        # 1. –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
        messages = self.task_agent.memory.chat_memory.messages
        if len(messages) < 4:
            print("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–µ—Å—Å–∏–∏.")
            return

        dialogue_history = "\n".join([f"{m.type}: {m.content}" for m in messages])

        # 2. –§–æ—Ä–º—É–ª–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
        analysis_prompt = f"""
–¢—ã ‚Äî AI-–∞–Ω–∞–ª–∏—Ç–∏–∫. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –¥–∏–∞–ª–æ–≥ –∏ –≤–µ—Ä–Ω–∏ –°–¢–†–û–ì–û JSON-–æ–±—ä–µ–∫—Ç —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –∫–ª—é—á–∞–º–∏:
- "session_summary": –ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –¥–∏–∞–ª–æ–≥–∞ –≤ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö.
- "key_topics": –°–ø–∏—Å–æ–∫ –∏–∑ 3-5 –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ–º –∏–ª–∏ —Å–ª–æ–≤, –æ–±—Å—É–∂–¥–∞–≤—à–∏—Ö—Å—è –≤ –¥–∏–∞–ª–æ–≥–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, ["–ø—Ä–æ–∫—Ä–∞—Å—Ç–∏–Ω–∞—Ü–∏—è", "python", "—Ç—Ä–µ–≤–æ–∂–Ω–æ—Å—Ç—å"]).
- "identified_patterns": –°–ø–∏—Å–æ–∫ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã—Ö –∏—Å–∫–∞–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –∑–∞–º–µ—á–µ–Ω—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, ["catastrophizing", "overgeneralization"]).

–î–∏–∞–ª–æ–≥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
{dialogue_history}
"""

        try:
            # 3. –í—ã–∑—ã–≤–∞–µ–º LLM –∏ –ø–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
            raw_response = self.task_agent.process("", context_memory=analysis_prompt)

            # --- –§–ò–ö–°: –û—á–∏—Å—Ç–∫–∞ JSON ---
            # –ò—â–µ–º, –≥–¥–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ø–µ—Ä–≤–∞—è { –∏ –≥–¥–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–Ω—è—è }
            start_idx = raw_response.find('{')
            end_idx = raw_response.rfind('}')
            
            if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                # –í—ã—Ä–µ–∑–∞–µ–º —Ç–æ–ª—å–∫–æ JSON-–æ–±—ä–µ–∫—Ç, –∏–≥–Ω–æ—Ä–∏—Ä—É—è —Ç–µ–∫—Å—Ç –¥–æ –∏ –ø–æ—Å–ª–µ
                clean_json = raw_response[start_idx : end_idx + 1]
                analysis_result = json.loads(clean_json)
            else:
                # –ï—Å–ª–∏ —Å–∫–æ–±–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ª–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
                raise json.JSONDecodeError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —á–∏—Å—Ç—ã–π JSON-–æ–±—ä–µ–∫—Ç –≤ –æ—Ç–≤–µ—Ç–µ LLM.", raw_response, 0)
            # --- –ö–û–ù–ï–¶ –§–ò–ö–°–ê ---

            # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –±–∞–∑—É
            self.memory.save_session_analysis(
                summary=analysis_result.get("session_summary", "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—é–º–µ."),
                topics=analysis_result.get("key_topics", []),
                patterns=analysis_result.get("identified_patterns", [])
            )
            print("–ê–Ω–∞–ª–∏–∑ —Å–µ—Å—Å–∏–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω.")
            self._report_cognitive_patterns()

        except (json.JSONDecodeError, TypeError) as e:
            print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å–µ—Å—Å–∏–∏: {e}. –û—Ç–≤–µ—Ç LLM: {raw_response}")
        except Exception as e:
            print(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å–µ—Å—Å–∏–∏: {e}")

    def _report_cognitive_patterns(self):
        """
        –í—ã–≤–æ–¥–∏—Ç –≤ –∫–æ–Ω—Å–æ–ª—å –æ—Ç—á–µ—Ç –æ –¥–∏–Ω–∞–º–∏–∫–µ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤.
        """
        print("\nüìä –ê–ù–ê–õ–ò–ó –ö–û–ì–ù–ò–¢–ò–í–ù–´–• –ü–ê–¢–¢–ï–†–ù–û–í (–¥–∏–Ω–∞–º–∏–∫–∞ –∑–∞ 30 –¥–Ω–µ–π):")

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ –∫–æ–≥–¥–∞-–ª–∏–±–æ –Ω–∞–±–ª—é–¥–∞–ª–∏—Å—å —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        all_patterns = self.memory.get_user_patterns()
        unique_pattern_names = sorted(list({p.pattern_name for p in all_patterns}))

        if not unique_pattern_names:
            print("–ü–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–∫–∞ –Ω–µ –Ω–∞–±–ª—é–¥–∞–ª–∏—Å—å.")
            return

        for pattern_name in unique_pattern_names:
            weight = self.memory.get_pattern_weight_over_time(pattern_name, window_days=30)
            if weight > 0:
                # –ü–æ–ª—É—á–∞–µ–º —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ –∏–º—è
                readable_name = next((rus_name for rus_name, internal_name in RUSSIAN_TO_INTERNAL_BIAS_MAP.items() if internal_name == pattern_name), pattern_name)

                print(f"  ‚Ä¢ {readable_name}: {weight}")
                if weight < 1.5:
                    print("    ‚úÖ –°–Ω–∏–∂–µ–Ω–∏–µ ‚Äî –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ–≥—Ä–µ—Å—Å–∏—Ä—É–µ—Ç.")
                elif weight > 4.0:
                    print("    ‚ö†Ô∏è –í—ã—Å–æ–∫–∞—è —á–∞—Å—Ç–æ—Ç–∞ ‚Äî —Ç—Ä–µ–±—É–µ—Ç—Å—è –≤–Ω–∏–º–∞–Ω–∏–µ.")
                else:
                    print("    üîÅ –ü–∞—Ç—Ç–µ—Ä–Ω —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É.")

    def end_session(self):
        """
        –ü—É–±–ª–∏—á–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å–µ—Å—Å–∏–∏.
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ main.py –ø—Ä–∏ —à—Ç–∞—Ç–Ω–æ–º –≤—ã—Ö–æ–¥–µ –∏–ª–∏ Ctrl+C.
        """
        print("\n–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã... –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–∏.")
        self._analyze_and_save_session()


