# –í –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞
from sqlalchemy.orm import Session
from database.models import User, CognitivePattern, DialogueEntry, UserProfile, UserTrait
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction, DefaultEmbeddingFunction
from database.db_connector import SessionLocal, chroma_client, get_chroma_collection, add_user_trait, get_user_traits
from datetime import datetime, timedelta
from sqlalchemy import desc

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
embedding_function = SentenceTransformerEmbeddingFunction(
    model_name="all-MiniLM-L6-v2"
)


class DynamicMemory:
    def __init__(self, user_id_stub: str):
        self.user_id_stub = user_id_stub
        self.db_session = SessionLocal()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –ø—Ä–æ—Ñ–∏–ª—è
        self.user = self._get_or_create_user()

        # üî• –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ø–∞–º—è—Ç—å ‚Äî –∏—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–æ–≤
        self.vector_collection = get_chroma_collection(f"dialogue_vector_{user_id_stub}")

        # ‚ö†Ô∏è history_collection ‚Äî –¥—É–±–ª—å? –ï—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –¥—Ä—É–≥–æ–º –º–µ—Å—Ç–µ ‚Äî –º–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å
        # self.history_collection = get_chroma_collection(f"history_{user_id_stub}")

        print(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id_stub} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")

    def _init_vector_collection(self):
        """–°–æ–∑–¥–∞—ë—Ç –∏–ª–∏ –ø–æ–ª—É—á–∞–µ—Ç –∫–æ–ª–ª–µ–∫—Ü–∏—é Chroma –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–æ–≤."""
        collection_name = f"dialogue_vector_{self.user_id_stub}"
        self.vector_collection = chroma_client.get_or_create_collection(
            name=collection_name,
            embedding_function=embedding_function
        )

    def _get_or_create_user(self):
        user = self.db_session.query(User).filter_by(user_id_stub=self.user_id_stub).first()
        if not user:
            user = User(user_id_stub=self.user_id_stub)
            self.db_session.add(user)
            self.db_session.commit()
        if not user.profile:
            profile = UserProfile(user_id=user.id)
            self.db_session.add(profile)
            self.db_session.commit()
            user.profile = profile
        return user

    def save_interaction(self, text: str, is_user: bool):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –≤ SQLite –∏ –≤–µ–∫—Ç–æ—Ä –≤ ChromaDB."""
        if not is_user:
            return  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≤–µ–∫—Ç–æ—Ä —Ç–æ–ª—å–∫–æ —Ä–µ–ø–ª–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        try:
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ SQLite
            entry = DialogueEntry(user_id=self.user.id, is_user=is_user, content=text)
            self.db_session.add(entry)
            self.db_session.commit()

            # üî• –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ ChromaDB
            self.vector_collection.add(
                ids=[str(entry.id)],
                documents=[text],
                metadatas=[{
                    "user_id": self.user.id,
                    "type": "user_input",
                    "timestamp": entry.timestamp.isoformat() if entry.timestamp else ""
                }]
            )
        except Exception as e:
            self.db_session.rollback()
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è: {e}")

    def save_cognitive_pattern(self, pattern_name: str, confidence: int, context: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–π –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö."""
        try:
            new_pattern = CognitivePattern(
                user_id=self.user.id,
                pattern_name=pattern_name,
                confidence_score=confidence,
                context=context
            )
            self.db_session.add(new_pattern)
            self.db_session.commit()
            print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω—ë–Ω –ø–∞—Ç—Ç–µ—Ä–Ω '{pattern_name}' (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence})")
        except Exception as e:
            self.db_session.rollback()
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞: {e}")

    
    def search_memories(self, query: str, n_results: int = 3) -> list:
        """–ò—â–µ—Ç –ø–æ—Ö–æ–∂–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ø–∞–º—è—Ç–∏."""
        try:
            results = self.vector_collection.query(
                query_texts=[query],
                n_results=n_results
            )
            # results["documents"][0] ‚Äî —ç—Ç–æ —Å–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
            return results["documents"][0] if results["documents"] else []
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤ –ø–∞–º—è—Ç–∏: {e}")
            return []

    def get_last_session_summary_for_prompt(self) -> str:
        summary = self.get_last_session_summary()
        if summary:
            return f"\n\nüìå –ò–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:\n{summary}"
        return ""

    def get_pattern_frequency(self, pattern_name: str) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑, —Å–∫–æ–ª—å–∫–æ –≤—Å—Ç—Ä–µ—á–∞–ª—Å—è –ø–∞—Ç—Ç–µ—Ä–Ω."""
        count = self.db_session.query(CognitivePattern).filter_by(
            user_id=self.user.id,
            pattern_name=pattern_name
        ).count()
        return count

    def get_user_patterns(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        try:
            return self.db_session.query(CognitivePattern).filter_by(user_id=self.user.id).all()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {e}")
            return []

    def get_pattern_weight(self, pattern_name: str) -> float:
        patterns = self.db_session.query(CognitivePattern).filter(...).all()
        weight = 0
        for p in patterns:
            days_ago = (datetime.utcnow() - p.observed_at).days
            decay = 0.9 ** (days_ago / 7)  # –ó–∞—Ç—É—Ö–∞–Ω–∏–µ –Ω–∞ 10% –≤ –Ω–µ–¥–µ–ª—é
            weight += decay
        return weight

    def get_pattern_weight_over_time(self, pattern_name: str, window_days: int = 30):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç "–≤–µ—Å" –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π —Å —É—á—ë—Ç–æ–º –∑–∞—Ç—É—Ö–∞–Ω–∏—è.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (–ó–ë–†).
        """
        patterns = (
            self.db_session.query(CognitivePattern)
            .filter_by(user_id=self.user.id, pattern_name=pattern_name)
            .order_by(CognitivePattern.observed_at)
            .all()
        )

        if not patterns:
            return 0.0

        total_weight = 0.0
        now = datetime.utcnow()

        for p in patterns:
            days_ago = (now - p.observed_at).days
            if days_ago > window_days:
                continue  # –≤–Ω–µ –æ–∫–Ω–∞
            decay = 0.9 ** (days_ago / 7)  # —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ (10% –≤ –Ω–µ–¥–µ–ª—é)
            total_weight += decay

        return round(total_weight, 2)

    def get_pattern_history(self, pattern_name: str, limit: int = 10):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º.
        –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–Ω–∞–º–∏–∫–∏.
        """
        patterns = (
            self.db_session.query(CognitivePattern)
            .filter_by(user_id=self.user.id, pattern_name=pattern_name)
            .order_by(desc(CognitivePattern.observed_at))
            .limit(limit)
            .all()
        )
        return patterns

    def get_pattern_frequency(self, pattern_name: str) -> int:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º.
        –£–∂–µ –µ—Å—Ç—å ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å.
        """
        count = self.db_session.query(CognitivePattern).filter_by(
            user_id=self.user.id,
            pattern_name=pattern_name
        ).count()
        return count

    def get_user_profile_summary(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ —Ç–æ–≥–æ, —á—Ç–æ –∑–Ω–∞–µ—Ç –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ."""
        summary_parts = []

        # –ò–º—è
        name = self.get_user_name()
        if name:
            summary_parts.append(f"–¢–µ–±—è –∑–æ–≤—É—Ç {name}.")

        # –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Ä–µ–∑—é–º–µ
        last_summary = self.get_last_session_summary()
        if last_summary:
            summary_parts.append(f"–í –ø—Ä–æ—à–ª—ã–π —Ä–∞–∑ –º—ã –≥–æ–≤–æ—Ä–∏–ª–∏ –æ: {last_summary}")

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã
        patterns = self.get_user_patterns()
        if patterns:
            unique_biases = {p.pattern_name for p in patterns}
            bias_names = {
                "black_and_white_thinking": "—á–µ—Ä–Ω–æ-–±–µ–ª–æ–µ –º—ã—à–ª–µ–Ω–∏–µ",
                "catastrophizing": "–∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∏–∑–∞—Ü–∏—è",
                "overgeneralization": "—á—Ä–µ–∑–º–µ—Ä–Ω–æ–µ –æ–±–æ–±—â–µ–Ω–∏–µ",
                "personalization": "–ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è"
            }
            human_biases = [bias_names.get(b, b) for b in unique_biases]
            if human_biases:
                summary_parts.append(f"–Ø –æ—Ç–º–µ—á–∞–ª —É —Ç–µ–±—è –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {', '.join(human_biases)}.")

        # –ß–∏—Å–ª–æ –¥–∏–∞–ª–æ–≥–æ–≤
        recent_messages = self.db_session.query(DialogueEntry).filter_by(user_id=self.user.id).count()
        if recent_messages > 0:
            summary_parts.append(f"–ú—ã —É–∂–µ –æ–±–º–µ–Ω—è–ª–∏—Å—å {recent_messages} —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏.")

        # –ß–µ—Ä—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        traits_summary = self.get_user_traits_summary()
        if traits_summary:
            summary_parts.append(traits_summary)

        # –ù–æ–≤—ã–µ –ø—Å–∏—Ö–æ–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
        if self.user.profile and self.user.profile.last_emotional_tone:
            summary_parts.append(f"–¢–≤–æ–π –ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω –±—ã–ª '{self.user.profile.last_emotional_tone}'.")
        if self.user.profile and self.user.profile.dominant_communication_style:
            summary_parts.append(f"–¢–≤–æ–π –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è ‚Äî '{self.user.profile.dominant_communication_style}'.")

        return " ".join(summary_parts) if summary_parts else "–ü–æ–∫–∞ —á—Ç–æ —è –º–∞–ª–æ –æ —Ç–µ–±–µ –∑–Ω–∞—é."

    def save_user_trait(self, trait_type: str, trait_description: str, confidence: int):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–æ–≤—É—é —á–µ—Ä—Ç—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –ë–î."""
        try:
            add_user_trait(
                db_session=self.db_session,
                user_id=self.user.id,
                trait_type=trait_type,
                trait_description=trait_description,
                confidence=confidence
            )
            print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —á–µ—Ä—Ç–∞ '{trait_type}': {trait_description}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —á–µ—Ä—Ç—ã: {e}")

    def get_user_traits_summary(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É —Å —á–µ—Ä—Ç–∞–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        try:
            traits = get_user_traits(self.db_session, self.user.id)
            if not traits:
                return ""

            summary_parts = []
            for trait in traits:
                summary_parts.append(f"[{trait.trait_type.capitalize()}] {trait.trait_description}")

            return "–ù–∞–±–ª—é–¥–∞–µ–º—ã–µ —á–µ—Ä—Ç—ã: " + "; ".join(summary_parts) + "."
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —á–µ—Ä—Ç: {e}")
            return ""

    def get_full_profile_context(self) -> str:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ: –∏–º—è, –ø—Ä–æ—à–ª—ã–µ —Ç–µ–º—ã, –ø–∞—Ç—Ç–µ—Ä–Ω—ã, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –∞–≤—Ç–æ–Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–∏ –∏ –∫–æ–º–∞–Ω–¥–µ /memory.
        """
        summary_parts = []

        # 1. –ò–º—è
        name = self.get_user_name()
        if name:
            summary_parts.append(f"–¢–µ–±—è –∑–æ–≤—É—Ç {name}.")

        # 2. –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Ä–µ–∑—é–º–µ —Å–µ—Å—Å–∏–∏
        last_summary = self.get_last_session_summary()
        if last_summary:
            summary_parts.append(f"–í –ø—Ä–æ—à–ª—ã–π —Ä–∞–∑ –º—ã –≥–æ–≤–æ—Ä–∏–ª–∏ –æ: {last_summary}")

        # 3. –ö–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        patterns = self.get_user_patterns()
        if patterns:
            unique_biases = {p.pattern_name for p in patterns}
            bias_names = {
                "black_and_white_thinking": "—á–µ—Ä–Ω–æ-–±–µ–ª–æ–µ –º—ã—à–ª–µ–Ω–∏–µ",
                "catastrophizing": "–∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∏–∑–∞—Ü–∏—è",
                "overgeneralization": "—á—Ä–µ–∑–º–µ—Ä–Ω–æ–µ –æ–±–æ–±—â–µ–Ω–∏–µ",
                "personalization": "–ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è",
                "hindsight_bias": "–æ—à–∏–±–∫–∞ —Ä–µ—Ç—Ä–æ—Å–ø–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–∑–≥–ª—è–¥–∞",
                "emotional_reasoning": "—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ",
                "mind_reading": "—á—Ç–µ–Ω–∏–µ –º—ã—Å–ª–µ–π"
            }
            human_biases = [bias_names.get(b, b) for b in sorted(unique_biases)]
            if human_biases:
                summary_parts.append(f"–Ø –æ—Ç–º–µ—á–∞–ª —É —Ç–µ–±—è –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {', '.join(human_biases)}.")

        # 4. –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        message_count = self.db_session.query(DialogueEntry).filter_by(user_id=self.user.id).count()
        if message_count > 0:
            summary_parts.append(f"–ú—ã —É–∂–µ –æ–±–º–µ–Ω—è–ª–∏—Å—å {message_count} —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏.")

        return " ".join(summary_parts) if summary_parts else "–ü–æ–∫–∞ —á—Ç–æ —è –º–∞–ª–æ –æ —Ç–µ–±–µ –∑–Ω–∞—é."

    def save_user_name(self, name: str):
        if not self.user.profile:
            self.user.profile = UserProfile(user_id=self.user.id)
            self.db_session.add(self.user.profile)
        self.user.profile.name = name
        self.db_session.commit()

    def get_user_name(self) -> str:
        return self.user.profile.name if self.user.profile and self.user.profile.name else None

    def save_session_summary(self, summary: str):
        if not self.user.profile:
            self.user.profile = UserProfile(user_id=self.user.id)
            self.db_session.add(self.user.profile)
        self.user.profile.last_session_summary = summary
        self.db_session.commit()

    def get_last_session_summary(self) -> str:
        return self.user.profile.last_session_summary if self.user.profile and self.user.profile.last_session_summary else None

    def save_psycholinguistic_features(self, emotional_tone: str, communication_style: str):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø—Å–∏—Ö–æ–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        """
        try:
            if not self.user.profile:
                # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –ø—Ä–æ—Ñ–∏–ª—å –µ—â–µ –Ω–µ —Å–æ–∑–¥–∞–Ω
                self.user.profile = UserProfile(user_id=self.user.id)
                self.db_session.add(self.user.profile)

            self.user.profile.last_emotional_tone = emotional_tone
            self.user.profile.dominant_communication_style = communication_style
            self.db_session.commit()
        except Exception as e:
            self.db_session.rollback()
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Å–∏—Ö–æ–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç—Ä–∏–∫: {e}")

    def __del__(self):
        if hasattr(self, 'db_session'):
            self.db_session.close()
