# –í –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞
from sqlalchemy.orm import Session
from database.models import User, CognitivePattern, DialogueEntry, UserProfile, UserTrait, SessionAnalysis
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction
from database.db_connector import SessionLocal, get_chroma_collection, add_user_trait, get_user_traits
from datetime import datetime
from sqlalchemy import desc
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º TaskAgent –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
from agents.task_agent import TaskAgent


class DynamicMemory:
    def __init__(self, user_id_stub: str, task_agent: TaskAgent):
        self.user_id_stub = user_id_stub
        self.db_session = SessionLocal()
        self.task_agent = task_agent # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –∞–≥–µ–Ω—Ç–∞

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –ø—Ä–æ—Ñ–∏–ª—è
        self.user = self._get_or_create_user()

        # –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ø–∞–º—è—Ç—å ‚Äî –∏—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–æ–≤
        self.vector_collection = get_chroma_collection(f"dialogue_vector_{user_id_stub}")
        print(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id_stub} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")

    def _init_vector_collection(self):
        """–°–æ–∑–¥–∞—ë—Ç –∏–ª–∏ –ø–æ–ª—É—á–∞–µ—Ç –∫–æ–ª–ª–µ–∫—Ü–∏—é Chroma –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–æ–≤."""
        collection_name = f"dialogue_vector_{self.user_id_stub}"
        self.vector_collection = chroma_client.get_or_create_collection(
            name=collection_name,
            embedding_function=embedding_function
        )

    def _get_or_create_user(self):
        user = self.db_session.query(User).filter_by(user_id_stub=self.user_id_stub).first()
        if not user:
            user = User(user_id_stub=self.user_id_stub)
            self.db_session.add(user)
            self.db_session.commit()
        if not user.profile:
            profile = UserProfile(user_id=user.id)
            self.db_session.add(profile)
            self.db_session.commit()
            user.profile = profile
        return user

    def _is_significant(self, text: str) -> bool:
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é LLM.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å—Ç–æ–∏—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—É—é –ø–∞–º—è—Ç—å.
        """
        # –ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–∞–≤–∏–ª–æ: —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç—Å–µ–∫–∞–µ–º —Å—Ä–∞–∑—É
        if len(text.split()) < 3:
            return False

        prompt = (
            "–û—Ü–µ–Ω–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—É—é –ø–ª–æ—Ç–Ω–æ—Å—Ç—å –∏ –≤–∞–∂–Ω–æ—Å—Ç—å —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ —à–∫–∞–ª–µ –æ—Ç 0.0 –¥–æ 1.0. "
            "–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —Ñ–∞–∫—Ç—ã, –≤–æ–ø—Ä–æ—Å—ã, —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è –∏–ª–∏ —Å–∏–ª—å–Ω—ã–µ —ç–º–æ—Ü–∏–∏, –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –≤—ã—Å–æ–∫–∏–π –±–∞–ª–ª. "
            "–ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è, –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏ –∏–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –∑–Ω–∞—á–∞—â–∏–µ —Ñ—Ä–∞–∑—ã ('–∞–≥–∞', '–æ–∫', '–Ω–µ –∑–Ω–∞—é') –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –Ω–∏–∑–∫–∏–π –±–∞–ª–ª. "
            "–í –æ—Ç–≤–µ—Ç –≤–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û —á–∏—Å–ª–æ, –Ω–∞–ø—Ä–∏–º–µ—Ä: 0.8"
        )
        try:
            response = self.task_agent.process(text, context_memory=prompt)
            score = float(response.strip())
            return score > 0.6
        except (ValueError, TypeError):
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –æ—Ç LLM, —Å—á–∏—Ç–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ–∑–Ω–∞—á–∏–º—ã–º
            return False

    def save_interaction(self, text: str, is_user: bool):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –≤ SQLite, –∞ –≤ ChromaDB ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–æ
        –ø—Ä–∏–∑–Ω–∞–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ –∑–Ω–∞—á–∏–º—ã–º.
        """
        try:
            # 1. –í—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ SQLite –¥–ª—è –ø–æ–ª–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏
            entry = DialogueEntry(user_id=self.user.id, is_user=is_user, content=text)
            self.db_session.add(entry)
            self.db_session.commit()

            # 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–∏–º—ã–µ —Ä–µ–ø–ª–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            if is_user and self._is_significant(text):
                self.vector_collection.add(
                    ids=[str(entry.id)],
                    documents=[text],
                    metadatas=[{
                        "user_id": self.user.id,
                        "type": "user_input",
                        "timestamp": entry.timestamp.isoformat() if entry.timestamp else ""
                    }]
                )
                print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∑–Ω–∞—á–∏–º–∞—è —Ä–µ–ø–ª–∏–∫–∞ –≤ ChromaDB: '{text[:50]}...'")

        except Exception as e:
            self.db_session.rollback()
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è: {e}")

    def save_cognitive_pattern(self, pattern_name: str, confidence: int, context: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–π –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö."""
        try:
            new_pattern = CognitivePattern(
                user_id=self.user.id,
                pattern_name=pattern_name,
                confidence_score=confidence,
                context=context
            )
            self.db_session.add(new_pattern)
            self.db_session.commit()
            print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω—ë–Ω –ø–∞—Ç—Ç–µ—Ä–Ω '{pattern_name}' (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence})")
        except Exception as e:
            self.db_session.rollback()
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞: {e}")

    
    def search_memories(self, query: str, n_results: int = 3) -> list:
        """–ò—â–µ—Ç –ø–æ—Ö–æ–∂–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ø–∞–º—è—Ç–∏."""
        try:
            results = self.vector_collection.query(
                query_texts=[query],
                n_results=n_results
            )
            # results["documents"][0] ‚Äî —ç—Ç–æ —Å–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
            return results["documents"][0] if results["documents"] else []
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤ –ø–∞–º—è—Ç–∏: {e}")
            return []

    def get_last_session_summary_for_prompt(self) -> str:
        summary = self.get_last_session_summary()
        if summary:
            return f"\n\nüìå –ò–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:\n{summary}"
        return ""

    def get_pattern_frequency(self, pattern_name: str) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑, —Å–∫–æ–ª—å–∫–æ –≤—Å—Ç—Ä–µ—á–∞–ª—Å—è –ø–∞—Ç—Ç–µ—Ä–Ω."""
        count = self.db_session.query(CognitivePattern).filter_by(
            user_id=self.user.id,
            pattern_name=pattern_name
        ).count()
        return count

    def get_user_patterns(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        try:
            return self.db_session.query(CognitivePattern).filter_by(user_id=self.user.id).all()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {e}")
            return []

    def get_pattern_weight(self, pattern_name: str) -> float:
        patterns = self.db_session.query(CognitivePattern).filter(...).all()
        weight = 0
        for p in patterns:
            days_ago = (datetime.utcnow() - p.observed_at).days
            decay = 0.9 ** (days_ago / 7)  # –ó–∞—Ç—É—Ö–∞–Ω–∏–µ –Ω–∞ 10% –≤ –Ω–µ–¥–µ–ª—é
            weight += decay
        return weight

    def get_pattern_weight_over_time(self, pattern_name: str, window_days: int = 30):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç "–≤–µ—Å" –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π —Å —É—á—ë—Ç–æ–º –∑–∞—Ç—É—Ö–∞–Ω–∏—è.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (–ó–ë–†).
        """
        patterns = (
            self.db_session.query(CognitivePattern)
            .filter_by(user_id=self.user.id, pattern_name=pattern_name)
            .order_by(CognitivePattern.observed_at)
            .all()
        )

        if not patterns:
            return 0.0

        total_weight = 0.0
        now = datetime.utcnow()

        for p in patterns:
            days_ago = (now - p.observed_at).days
            if days_ago > window_days:
                continue  # –≤–Ω–µ –æ–∫–Ω–∞
            decay = 0.9 ** (days_ago / 7)  # —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ (10% –≤ –Ω–µ–¥–µ–ª—é)
            total_weight += decay

        return round(total_weight, 2)

    def get_pattern_history(self, pattern_name: str, limit: int = 10):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º.
        –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–Ω–∞–º–∏–∫–∏.
        """
        patterns = (
            self.db_session.query(CognitivePattern)
            .filter_by(user_id=self.user.id, pattern_name=pattern_name)
            .order_by(desc(CognitivePattern.observed_at))
            .limit(limit)
            .all()
        )
        return patterns

    def get_pattern_frequency(self, pattern_name: str) -> int:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º.
        –£–∂–µ –µ—Å—Ç—å ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å.
        """
        count = self.db_session.query(CognitivePattern).filter_by(
            user_id=self.user.id,
            pattern_name=pattern_name
        ).count()
        return count

    def get_user_profile_summary(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ —Ç–æ–≥–æ, —á—Ç–æ –∑–Ω–∞–µ—Ç –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ."""
        summary_parts = []

        # –ò–º—è
        name = self.get_user_name()
        if name:
            summary_parts.append(f"–¢–µ–±—è –∑–æ–≤—É—Ç {name}.")

        # –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Ä–µ–∑—é–º–µ
        last_summary = self.get_last_session_summary()
        if last_summary:
            summary_parts.append(f"–í –ø—Ä–æ—à–ª—ã–π —Ä–∞–∑ –º—ã –≥–æ–≤–æ—Ä–∏–ª–∏ –æ: {last_summary}")

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã
        patterns = self.get_user_patterns()
        if patterns:
            unique_biases = {p.pattern_name for p in patterns}
            bias_names = {
                "black_and_white_thinking": "—á–µ—Ä–Ω–æ-–±–µ–ª–æ–µ –º—ã—à–ª–µ–Ω–∏–µ",
                "catastrophizing": "–∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∏–∑–∞—Ü–∏—è",
                "overgeneralization": "—á—Ä–µ–∑–º–µ—Ä–Ω–æ–µ –æ–±–æ–±—â–µ–Ω–∏–µ",
                "personalization": "–ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è"
            }
            human_biases = [bias_names.get(b, b) for b in unique_biases]
            if human_biases:
                summary_parts.append(f"–Ø –æ—Ç–º–µ—á–∞–ª —É —Ç–µ–±—è –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {', '.join(human_biases)}.")

        # –ß–∏—Å–ª–æ –¥–∏–∞–ª–æ–≥–æ–≤
        recent_messages = self.db_session.query(DialogueEntry).filter_by(user_id=self.user.id).count()
        if recent_messages > 0:
            summary_parts.append(f"–ú—ã —É–∂–µ –æ–±–º–µ–Ω—è–ª–∏—Å—å {recent_messages} —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏.")

        # –ß–µ—Ä—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        traits_summary = self.get_user_traits_summary()
        if traits_summary:
            summary_parts.append(traits_summary)

        # –ù–æ–≤—ã–µ –ø—Å–∏—Ö–æ–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
        if self.user.profile and self.user.profile.last_emotional_tone:
            summary_parts.append(f"–¢–≤–æ–π –ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω –±—ã–ª '{self.user.profile.last_emotional_tone}'.")
        if self.user.profile and self.user.profile.dominant_communication_style:
            summary_parts.append(f"–¢–≤–æ–π –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è ‚Äî '{self.user.profile.dominant_communication_style}'.")

        return " ".join(summary_parts) if summary_parts else "–ü–æ–∫–∞ —á—Ç–æ —è –º–∞–ª–æ –æ —Ç–µ–±–µ –∑–Ω–∞—é."

    def reinforce_user_trait(self, trait_type: str, trait_description: str, confidence: int):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–ª–∏ —É—Å–∏–ª–∏–≤–∞–µ—Ç "–≥–∏–ø–æ—Ç–µ–∑—É" –æ —á–µ—Ä—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        –ï—Å–ª–∏ –≥–∏–ø–æ—Ç–µ–∑–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑, –æ–Ω–∞ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è "—Ñ–∞–∫—Ç–æ–º".
        """
        try:
            # –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –≥–∏–ø–æ—Ç–µ–∑—É
            existing_trait = self.db_session.query(UserTrait).filter_by(
                user_id=self.user.id,
                trait_description=trait_description
            ).first()

            if existing_trait:
                # –ï—Å–ª–∏ –Ω–∞—à–ª–∏, –∏ —ç—Ç–æ –≤—Å–µ –µ—â–µ –≥–∏–ø–æ—Ç–µ–∑–∞, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫
                if existing_trait.status == 'hypothesis':
                    existing_trait.confirmation_count += 1
                    existing_trait.confidence = max(existing_trait.confidence, confidence) # –û–±–Ω–æ–≤–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø–æ—Ä–∞ –ª–∏ —Å–¥–µ–ª–∞—Ç—å –≥–∏–ø–æ—Ç–µ–∑—É —Ñ–∞–∫—Ç–æ–º
                    if existing_trait.confirmation_count >= 3:
                        existing_trait.status = 'fact'
                        print(f"üî• –ì–∏–ø–æ—Ç–µ–∑–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞ –∫–∞–∫ —Ñ–∞–∫—Ç: '{trait_description}'")
                    else:
                        print(f"üîÑ –ì–∏–ø–æ—Ç–µ–∑–∞ —É—Å–∏–ª–µ–Ω–∞: '{trait_description}' (–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π: {existing_trait.confirmation_count})")
            else:
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –≥–∏–ø–æ—Ç–µ–∑—É
                new_trait = UserTrait(
                    user_id=self.user.id,
                    trait_type=trait_type,
                    trait_description=trait_description,
                    confidence=confidence,
                    status='hypothesis',
                    confirmation_count=1
                )
                self.db_session.add(new_trait)
                print(f"üí° –ù–æ–≤–∞—è –≥–∏–ø–æ—Ç–µ–∑–∞: '{trait_description}'")

            self.db_session.commit()

        except Exception as e:
            self.db_session.rollback()
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É—Å–∏–ª–µ–Ω–∏–∏ —á–µ—Ä—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")

    def get_user_traits_summary(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É —Å —á–µ—Ä—Ç–∞–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        try:
            traits = get_user_traits(self.db_session, self.user.id)
            if not traits:
                return ""

            summary_parts = []
            for trait in traits:
                summary_parts.append(f"[{trait.trait_type.capitalize()}] {trait.trait_description}")

            return "–ù–∞–±–ª—é–¥–∞–µ–º—ã–µ —á–µ—Ä—Ç—ã: " + "; ".join(summary_parts) + "."
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —á–µ—Ä—Ç: {e}")
            return ""

    def get_full_profile_context(self) -> str:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ: –∏–º—è, –ø—Ä–æ—à–ª—ã–µ —Ç–µ–º—ã, –ø–∞—Ç—Ç–µ—Ä–Ω—ã, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –∞–≤—Ç–æ–Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–∏ –∏ –∫–æ–º–∞–Ω–¥–µ /memory.
        """
        summary_parts = []

        # 1. –ò–º—è
        name = self.get_user_name()
        if name:
            summary_parts.append(f"–¢–µ–±—è –∑–æ–≤—É—Ç {name}.")

        # 2. –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Ä–µ–∑—é–º–µ —Å–µ—Å—Å–∏–∏
        last_summary = self.get_last_session_summary()
        if last_summary:
            summary_parts.append(f"–í –ø—Ä–æ—à–ª—ã–π —Ä–∞–∑ –º—ã –≥–æ–≤–æ—Ä–∏–ª–∏ –æ: {last_summary}")

        # 3. –ö–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        patterns = self.get_user_patterns()
        if patterns:
            unique_biases = {p.pattern_name for p in patterns}
            bias_names = {
                "black_and_white_thinking": "—á–µ—Ä–Ω–æ-–±–µ–ª–æ–µ –º—ã—à–ª–µ–Ω–∏–µ",
                "catastrophizing": "–∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∏–∑–∞—Ü–∏—è",
                "overgeneralization": "—á—Ä–µ–∑–º–µ—Ä–Ω–æ–µ –æ–±–æ–±—â–µ–Ω–∏–µ",
                "personalization": "–ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è",
                "hindsight_bias": "–æ—à–∏–±–∫–∞ —Ä–µ—Ç—Ä–æ—Å–ø–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–∑–≥–ª—è–¥–∞",
                "emotional_reasoning": "—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ",
                "mind_reading": "—á—Ç–µ–Ω–∏–µ –º—ã—Å–ª–µ–π"
            }
            human_biases = [bias_names.get(b, b) for b in sorted(unique_biases)]
            if human_biases:
                summary_parts.append(f"–Ø –æ—Ç–º–µ—á–∞–ª —É —Ç–µ–±—è –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {', '.join(human_biases)}.")

        # 4. –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        message_count = self.db_session.query(DialogueEntry).filter_by(user_id=self.user.id).count()
        if message_count > 0:
            summary_parts.append(f"–ú—ã —É–∂–µ –æ–±–º–µ–Ω—è–ª–∏—Å—å {message_count} —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏.")

        return " ".join(summary_parts) if summary_parts else "–ü–æ–∫–∞ —á—Ç–æ —è –º–∞–ª–æ –æ —Ç–µ–±–µ –∑–Ω–∞—é."

    def save_user_name(self, name: str):
        if not self.user.profile:
            self.user.profile = UserProfile(user_id=self.user.id)
            self.db_session.add(self.user.profile)
        self.user.profile.name = name
        self.db_session.commit()

    def get_user_name(self) -> str:
        return self.user.profile.name if self.user.profile and self.user.profile.name else None

    def save_session_analysis(self, summary: str, topics: list, patterns: list):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Å–µ—Å—Å–∏–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.
        """
        try:
            analysis_entry = SessionAnalysis(
                user_id=self.user.id,
                session_summary=summary,
                key_topics=", ".join(topics),
                identified_patterns=", ".join(patterns)
            )
            self.db_session.add(analysis_entry)
            self.db_session.commit()
        except Exception as e:
            self.db_session.rollback()
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∞–Ω–∞–ª–∏–∑–∞ —Å–µ—Å—Å–∏–∏: {e}")

    def get_recent_session_analyses(self, limit: int = 5) -> list:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –∑–∞–ø–∏—Å–µ–π –∞–Ω–∞–ª–∏–∑–∞ —Å–µ—Å—Å–∏–π –¥–ª—è –≤—ã—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏.
        """
        return self.db_session.query(SessionAnalysis).filter_by(
            user_id=self.user.id
        ).order_by(desc(SessionAnalysis.ended_at)).limit(limit).all()

    def save_session_summary(self, summary: str):
        if not self.user.profile:
            self.user.profile = UserProfile(user_id=self.user.id)
            self.db_session.add(self.user.profile)
        self.user.profile.last_session_summary = summary
        self.db_session.commit()

    def get_last_session_summary(self) -> str:
        return self.user.profile.last_session_summary if self.user.profile and self.user.profile.last_session_summary else None

    def save_psycholinguistic_features(self, emotional_tone: str, communication_style: str):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø—Å–∏—Ö–æ–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        """
        try:
            if not self.user.profile:
                # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –ø—Ä–æ—Ñ–∏–ª—å –µ—â–µ –Ω–µ —Å–æ–∑–¥–∞–Ω
                self.user.profile = UserProfile(user_id=self.user.id)
                self.db_session.add(self.user.profile)

            self.user.profile.last_emotional_tone = emotional_tone
            self.user.profile.dominant_communication_style = communication_style
            self.db_session.commit()
        except Exception as e:
            self.db_session.rollback()
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Å–∏—Ö–æ–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç—Ä–∏–∫: {e}")

    def __del__(self):
        if hasattr(self, 'db_session'):
            self.db_session.close()
