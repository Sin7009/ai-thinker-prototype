import os
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from database.db_connector import chroma_client
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction

# –û—Å—Ç–∞–≤–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (–æ–Ω–∏ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –∏ –±—ã—Å—Ç—Ä—ã–µ)
embedding_function = SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-v2")

class MethodologyAgent:
    """
    –ê–≥–µ–Ω—Ç-–ü–∞—Ä—Ç–Ω–µ—Ä (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç '—É–º–Ω—É—é' –º–æ–¥–µ–ª—å —Å Reasoning, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞).
    """
    def __init__(self, user_id: str = "default_user", model_name: str = "deepseek/deepseek-r1:free"):
        self.chat = ChatOpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=os.environ.get('OPENROUTER_API_KEY'),
            model=model_name,
            temperature=0.6,
            default_headers={"HTTP-Referer": "https://github.com/ai-thinker"}
        )

        collection_name = f"methodology_memory_{user_id}"
        self.collection = chroma_client.get_or_create_collection(
            name=collection_name,
            embedding_function=embedding_function
        )
        self.message_history = []
        print(f"MethodologyAgent –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω ({model_name}).")

    def execute(self, system_prompt: str, user_prompt: str) -> str:
        try:
            # RAG (–ø–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
            results = self.collection.query(query_texts=[user_prompt], n_results=3)
            relevant_contexts = results["documents"][0] if results["documents"] else []

            context_block = ""
            if relevant_contexts:
                context_block = "üìå –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø—Ä–æ—à–ª–æ–≥–æ:\n" + "\n".join([f"- {ctx}" for ctx in relevant_contexts])

            messages = [SystemMessage(content=system_prompt + "\n" + context_block)]

            # –ö—Ä–∞—Ç–∫–∞—è –∏—Å—Ç–æ—Ä–∏—è —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏
            for role, content in self.message_history[-4:]:
                if role == "user":
                    messages.append(HumanMessage(content=content))
                else:
                    messages.append(SystemMessage(content=content)) # –ò–ª–∏ AIMessage

            messages.append(HumanMessage(content=user_prompt))

            response = self.chat.invoke(messages)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–º—è—Ç—å
            self.collection.add(
                ids=[f"turn_{len(self.message_history)}"],
                documents=[user_prompt + " -> " + response.content],
                metadatas=[{"type": "interaction"}]
            )
            self.message_history.append(("user", user_prompt))
            self.message_history.append(("ai", response.content))

            return response.content

        except Exception as e:
            print(f"MethodologyAgent Error: {e}")
            return "–û—à–∏–±–∫–∞ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —è–¥—Ä–∞."

    def clear_memory(self):
        self.message_history = []
