import json
import re
from typing import List, Dict, Any

class DetectorAgent:
    """
    Максимально расширенный агент для диагностики когнитивных искажений (Контур Б).
    
    Использует расширенный словарь психолингвистических маркеров (лексических и 
    синтаксических) для детекции большего числа искажений.
    """
    def __init__(self):
        """
        Инициализирует агента со словарем паттернов когнитивных искажений.
        """
        self.bias_patterns: Dict[str, Dict[str, Any]] = {
            # === Базовые искажения (из прошлой версии) ===
            "black_and_white_thinking": {
                "name": "Черно-белое мышление (Дихотомическое мышление)",
                "type": "keywords",
                "markers": [
                    "все", "никто", "абсолютно", "полностью", "совершенно",
                    "ничего", "полный ноль", "идеально", "провал", "бесполезно"
                ]
            },
            "overgeneralization": {
                "name": "Сверхобобщение",
                "type": "keywords",
                "markers": [
                    "всегда", "никогда", "постоянно", "вечно", "всю жизнь",
                    "каждый раз", "ни разу"
                ]
            },
            "catastrophizing": {
                "name": "Катастрофизация",
                "type": "keywords",
                "markers": [
                    "ужас", "кошмар", "катастрофа", "всё пропало",
                    "конец света", "невыносимо", "ужасно", "невероятно"
                ]
            },
            "mind_reading": {
                "name": "Чтение мыслей",
                "type": "regex",
                "markers": [
                    r"(он|она|они) (думает|думают|считает|считают),? что я",
                    r"я знаю,? что (он|она|они) (думает|думают|хочет|хотят)",
                    r"(ему|ей|им) (точно|наверняка) (не понравилось|не нравится)",
                    r"(он|она|они) (наверняка|скорее всего) (решил|решили)",
                    r"он посмотрел на меня так,? будто"
                ]
            },
            "personalization": {
                "name": "Персонализация",
                "type": "regex",
                "markers": [
                    r"это (вс[её])? из-за меня",
                    r"я (виноват|виновата),? что",
                    r"если бы не я",
                    r"во мне причина"
                ]
            },
            "hindsight_bias": {
                "name": "Ошибка ретроспективного взгляда ('Я так и знал')",
                "type": "keywords",
                "markers": [
                    "я так и знал", "было же очевидно", "сразу было понятно",
                    "по-другому и быть не могло", "нужно было", "следовало (сделать)"
                ]
            },
            "emotional_reasoning": {
                "name": "Эмоциональное обоснование",
                "type": "regex",
                "markers": [
                    r"я чувствую,? что я (.+?),? (значит|поэтому) я", # "Я чувствую, что я дурак, значит я дурак"
                    r"я чувствую себя (глупо|ужасно|неудачником|подавленным)",
                    r"мне кажется,? это (провал|ужасно),? значит так и есть"
                ]
            },

            # === Новые расширенные искажения ===
            
            "availability_heuristic": {
                "name": "Эвристика доступности",
                "type": "regex",
                "markers": [
                    r"я (только что|вчера|недавно) (видел|слышал|читал) про (.+?),? (поэтому|теперь|значит) (они|это) (очень|всегда)",
                    r"помню был случай"
                ]
            },
            "status_quo_bias": {
                "name": "Отклонение в сторону статуса кво",
                "type": "keywords",
                "markers": [
                    "зачем менять", "пусть будет как есть", "всегда так делали",
                    "раньше так работало", "не будем ничего трогать", "лучше не рисковать"
                ]
            },
            "gamblers_fallacy": {
                "name": "Ошибка игрока",
                "type": "regex",
                "markers": [
                    r"уже (несколько|пять|столько) раз (.+?),? значит (сейчас|следующий) (точно|должен)", # "уже 5 раз подряд решка, значит сейчас точно орел"
                    r"не может же (постоянно|вечно)"
                ]
            },
            "survivorship_bias": {
                "name": "Ошибка выжившего",
                "type": "regex",
                "markers": [
                    r"у (него|нее|них) (же)? получилось, (значит|поэтому) и я (смогу|получится)",
                    r"раз (он|они) (смог|смогли), то (любой сможет|и я смогу)",
                    r"все (успешные люди|миллионеры) (делали|говорят)"
                ]
            },
            "false_consensus_effect": {
                "name": "Эффект ложного консенсуса",
                "type": "keywords",
                "markers": [
                    "все (же|и так) (знают|понимают|считают)",
                    "любой (скажет|знает|согласится)",
                    "для всех очевидно",
                    "нормальные люди"
                ]
            },
            "halo_effect": {
                "name": "Эффект ореола",
                "type": "regex",
                "markers": [
                    r"он (такой|такая) (умный|красивая|успешный),? (значит|поэтому) (он|она) (прав|не может ошибаться)",
                    r"человек, который (смог|создал) (.+?),? не (может|станет)"
                ]
            }
        }
        print("DetectorAgent (Максимально расширенный) инициализирован.")

    def _detect_keywords(self, text_lower: str, markers: List[str]) -> List[str]:
        """Вспомогательная функция для поиска по ключевым словам."""
        # Используем \b (границы слова) для более точного поиска
        # (например, чтобы "все" не срабатывало на "всегда")
        found = [
            marker for marker in markers 
            if re.search(r'\b' + re.escape(marker) + r'\b', text_lower)
        ]
        return found

    def _detect_regex(self, text_lower: str, patterns: List[str]) -> List[str]:
        """Оптимизированная функция для поиска по регулярным выражениям."""
        found = []
        for pattern in patterns:
            # re.finditer возвращает итератор по всем совпадениям
            matches = re.finditer(pattern, text_lower)
            for match in matches:
                # match.group(0) - это полный текст совпадения
                found.append(match.group(0))
        
        # Возвращаем уникальные совпавшие маркеры
        return list(set(found))

    def analyze(self, text: str) -> str:
        """
        Анализирует текст на наличие когнитивных искажений.
        Возвращает JSON-строку с результатами.
        """
        detected_patterns: List[Dict[str, Any]] = []
        text_lower = text.lower()

        for bias_key, config in self.bias_patterns.items():
            found_markers = []
            if config["type"] == "keywords":
                found_markers = self._detect_keywords(text_lower, config["markers"])
            elif config["type"] == "regex":
                found_markers = self._detect_regex(text_lower, config["markers"])

            if found_markers:
                # Уверенность: база 80% + 3% за каждый маркер, максимум 98%
                confidence = min(80 + len(found_markers) * 3, 98)
                
                detected_patterns.append({
                    "bias": bias_key,
                    "name": config["name"],
                    "confidence": confidence,
                    # Показываем до 3-х маркеров для краткости
                    "context": f"Обнаружено: {', '.join(found_markers[:3])}"
                })

        if not detected_patterns:
            return json.dumps([])

        # ensure_ascii=False для корректного отображения кириллицы
        # indent=2 для читаемого JSON
        return json.dumps(detected_patterns, ensure_ascii=False, indent=2)